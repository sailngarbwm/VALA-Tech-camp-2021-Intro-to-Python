{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intensive-given",
   "metadata": {},
   "source": [
    "# Final practical example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-front",
   "metadata": {},
   "source": [
    "### What we know so far:\n",
    "- all librarians are data scientists\n",
    "- coding in python isn't that much different from working with a spreadsheet\n",
    "- we know how to create text data and numerical data, and store it in a string, \n",
    "- we know how to store data in lists, as well as access one item in the list, or a *slice* of items\n",
    "- we can recite the 3 pet peeves of python\n",
    "- we know how to store data in dictionaries, and access them via their keys\n",
    "\n",
    "### What we will learn now:\n",
    "- We will learn how to use two really nifty python libraries to help us with turning a csv in to dublin core xml\n",
    "- We will practice planning a coding script\n",
    "- we will use our knowledge to create a jupyter notebook to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-jamaica",
   "metadata": {},
   "source": [
    "## The task- Turn a spreadsheet of metadata into dublin core\n",
    "\n",
    "Any good coding project starts out with some pseudo code to think about what to write before you write it, think of it like outlining a paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-coach",
   "metadata": {},
   "source": [
    "### Example pseudo code\n",
    "Write in order the things you need your code to run:\n",
    "\n",
    "**Step 0:** Upload the libraries you need to run your script\n",
    "\n",
    "**Step 1:** Upload data/ metadata\n",
    "\n",
    "**Step 2:** Preprocess data/ metadata... this could be multiple steps\n",
    "\n",
    "**Step 3:** Create the desired output (a csv, a graph, a map, an xml file etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-orientation",
   "metadata": {},
   "source": [
    "### Group discussion: Write specific pseudocode for our exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-freeze",
   "metadata": {},
   "source": [
    "### Step 1: Some help with opening a csv, introducing the special powers of pandas?:\n",
    "\n",
    "We first need to upload data from a csv into Python, in order to do that we will use one of the most powerful packages used in Python called, **Pandas**, which is the go to package for working with spreadsheet/tabular \"tidy\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# this file is in the same folder as the notebook\n",
    "df = pd.read_csv(\"example_data/iris.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-steps",
   "metadata": {},
   "source": [
    "**Sidebar:** How does python know where that csv is? Every running python kernel has a a folder in your computer that it is working in (this can be changed using the command os.chdir() but we won't need that here. When you open up and start a jupyter notebook, the kernel starts running in the folder it is working then. In that case, you can open up a csv in the same folder by just using a string of the file name in pd.read_csv, or use a relative path (like the example above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-theta",
   "metadata": {},
   "source": [
    "You can really just think of a pandas \"dataframe\" as a dictionary, full of lists (actually numpy arrays but don't worry about that right now!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out one of the columns\n",
    "type(df) # what did we make here?\n",
    "df['sepal_length'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-battlefield",
   "metadata": {},
   "source": [
    "In fact, you can even turn it into a dictionary full of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jgarber_respitch.workshop_tools import convert_df_row_to_dictionary\n",
    "\n",
    "help(convert_df_row_to_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df_row_to_dictionary(df,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-atmosphere",
   "metadata": {},
   "source": [
    "### Data frames have attributes as well as methods:\n",
    "\n",
    "Attributes are kind of like variables that are stored within the object, and are accessed kind of like a method but without the `()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-stuart",
   "metadata": {},
   "source": [
    "### Exercise 5.1 open your first csv:\n",
    "1. open the mild_DC_dataset.csv in the exercise_data folder\n",
    "2. find out what column names the dataset has\n",
    "3. take a look at the top five rows of the dataset (bonus points for looking at the bottom 5 rows)\n",
    "4. find out how big the dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the dataset in exercise_data/easy_DC_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the columns of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the top five rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out how big the dataset is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-liability",
   "metadata": {},
   "source": [
    "### Step -1: Outputing an xml file:\n",
    "\n",
    "I said at the beginning that usually you have to create your own special powers by writing your own code to do what you want, but this time I am wrong. Luckily some really clever people have already written a package to create Simple Dublin Core xml files called dcxml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcxml import simpledc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-edward",
   "metadata": {},
   "source": [
    "All you need to do is feed it a dictionary with these ***specific*** keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        'contributors' : ['CERN'],\n",
    "        'coverage' : ['Geneva'],\n",
    "        'creators' : ['CERN'],\n",
    "        'dates' : ['2002'],\n",
    "        'descriptions' : ['Simple Dublin Core generation'],\n",
    "        'formats' : ['application/xml'],\n",
    "        'identifiers' : ['dublin-core'],\n",
    "        'languages' : ['en'],\n",
    "        'publishers' : ['CERN'],\n",
    "        'relations' : ['Invenio Software'],\n",
    "        'rights' : ['MIT'],\n",
    "        'sources' : ['Python'],\n",
    "        'subject' : ['XML'],\n",
    "        'titles' : ['Dublin Core XML'],\n",
    "        'types' : ['Software'],\n",
    "         'extra': ['extra']\n",
    "       }\n",
    "\n",
    "xml = simpledc.tostring(data)\n",
    "print(xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-driving",
   "metadata": {},
   "source": [
    "### Exercise: Have a go with this library\n",
    "What happens when you don't have all the metadata fields listed as dictionary keys in data above? will it still create an xml?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "danish-password",
   "metadata": {},
   "source": [
    "### Final Project Part one: Turn the easy_DC_dataset , row number 5, into xml:\n",
    "1. Update the pseudocode for this project now that we have our two magic powers, Pandas and dcxml (we will do this together)\n",
    "2. write a script to turn the dataframe into xml formatted string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-burton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-manor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "three-treatment",
   "metadata": {},
   "source": [
    "### Extra Credit Exercises: Turn the medium_DC_dataset.csv, row number 10, into xml\n",
    "\n",
    "This one you may have to double check to see if the column names are right, if they aren't then check out the [dataframe.rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) method, and perhaps check the dictionary we created in part 4 as a help...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-chamber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-malawi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "verbal-medline",
   "metadata": {},
   "source": [
    "### Homework, getting Loopy!\n",
    "\n",
    "It's pretty annoying to go through each row one at a time right? We totally agree! Thats why all languages have loops, which allows one to repeat code for a specified or calculated number of times. One can use a `for` loop, to repeat code ***for*** as many times as specified when the loop is created.\n",
    "\n",
    "Please check out my youtube video on the subject:\n",
    "\n",
    "https://youtu.be/-NM7jO_QXa0\n",
    "\n",
    "These things are often done with a range, which is a way to make a python object that gives you all the integers within a given range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in range(1,10):\n",
    "    print(number) # is the number 10 printed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-studio",
   "metadata": {},
   "source": [
    "now that we can create a range of integers, what if we also used those integers to go through every row of a our dataframe, and convert it into an xml? give that a go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-attendance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "marked-coupon",
   "metadata": {},
   "source": [
    "# CONGRATULATIONS FOR REACHING THE END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-florida",
   "metadata": {},
   "source": [
    "And thus begins the start of your journey into the world of Python. The coming weeks and months are going to be frustrating - you know that you *can* do something, but you *just can't quite* remember how it's done. Or maybe you need to keep looking up the simple things. And general syntax is going to be horrendous to remember."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-cannon",
   "metadata": {},
   "source": [
    "![image.png](https://github.com/sailngarbwm/VALA-Tech-camp-2021-Intro-to-Python/raw/main/Imbedded%20Pics/end_cartoon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-memorabilia",
   "metadata": {},
   "source": [
    "### What we have learned\n",
    "- All librarians are data scientists\n",
    "- Coding is not that much different than doing things in excel, it is in the end easier to read, and has way way way more capabilities\n",
    "- we learned about the types of data, and using functions and methods\n",
    "- we can recite the 3 pet peeves of python\n",
    "- we can store and use data and other python objects in lists and dictionaries\n",
    "- We can use pandas to bring csv data into python, and manipulate that data\n",
    "- We can use dcxml to create Dublin Core files\n",
    "- we are ready to continue the lifelong learning journey into coding with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-worry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
